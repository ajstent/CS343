{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import make_lupton_rgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a picture.\n",
    "\n",
    "We can use pictures like this to train a model to:\n",
    "1. Determine whether a picture contains a seven or not\n",
    "2. Find instances of seven in a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "image_r = rng.random((32,32))\n",
    "image_g = rng.random((32,32))\n",
    "image_b = rng.random((32,32))\n",
    "image = make_lupton_rgb(image_r, image_g, image_b, stretch=1)\n",
    "seven = [[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [1, 4], [2, 3], [3,2], [4, 2], [5, 1], [6, 1], [7, 1], [8, 1]]\n",
    "randomx = np.random.randint(2, 20)\n",
    "randomy = np.random.randint(3, 20)\n",
    "for pixel in seven:\n",
    "    image[randomx+pixel[0], randomy+pixel[1]] = (0, 0, 0)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this picture:\n",
    "* What is the shape?\n",
    "* Where is the seven?\n",
    "* How would you linearize the array for feeding into a MLP?\n",
    "* How wide would be the input layer of that MLP?\n",
    "* What would be the minimum distance between R/G/B valued pixels in your linearization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "# row major\n",
    "print(len(image.flatten()))\n",
    "print(image.shape[0]*image.shape[1]*image.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinan():\n",
    "    image_r = np.ones((3,3))\n",
    "    image_g = np.ones((3,3)) * 2\n",
    "    image_b = np.ones((3,3)) * 3\n",
    "    image = make_lupton_rgb(image_r, image_g, image_b, stretch=1)\n",
    "    print(image.shape)\n",
    "    flat = image.flatten(order='F') # cf order='C'\n",
    "    print(flat.shape)\n",
    "    print(flat)\n",
    "sinan()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have established that we need a model that is:\n",
    "* translation invariant\n",
    "* efficient \n",
    "* capable of capturing local context\n",
    "\n",
    "We can do this by using **convolutional neural networks**. Today we are going to focus on the nature of *convolution*. \n",
    "\n",
    "*Convolutions* construct features over local regions in the input data using convolution *kernels*. Here's a sample kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[-1,-1,-1], [-1,8,-1], [-1,-1,-1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few minutes and define a function that will apply this kernel starting from the top left of the input image and working to the bottom right. At each stop, if the kernel is $Y$ and the subarray of the picture is $X$, calculate $\\sum_{i,j} x_{i,j}*y_{i,j}$.\n",
    "* What is the shape of the output of the convolution?\n",
    "* Does it give information useful for finding sevens?\n",
    "* How do you apply the kernel across R/G/B?\n",
    "* What do you do at the edges?\n",
    "* Does this kernel really need to be applied pixel by pixel, or could we skip some pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel, channels=[0,1,2], stride=0, pad=0):\n",
    "    res = []\n",
    "    for i in range(image.shape[0]-kernel.shape[0]):\n",
    "        for j in range(image.shape[1]-kernel.shape[1]):\n",
    "            for k in range(image.shape[2]):\n",
    "                res[i,j,k] = np.multiply(image[i:i+kernel.shape[0], j:j+kernel.shape[1]], kernel)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pause a minute and talk about:\n",
    "* *padding*\n",
    "* *channels*\n",
    "* *stride* - and how this affects dimensionality of output of convolution\n",
    "* *cross-correlation*\n",
    "* *feature map*\n",
    "* *receptive field*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* https://nicholasrui.com/2017/12/18/convolutions-and-the-game-of-life/\n",
    "* https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac\n",
    "* https://deeplizard.com/resource/pavq7noze2\n",
    "* https://poloclub.github.io/cnn-explainer/\n",
    "* http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf\n",
    "\n",
    "CNNs can get big: https://theaisummer.com/cnn-architectures/\n",
    "\n",
    "CNNs are not just useful for images:\n",
    "* https://spacy.io/api/architectures#textcat\n",
    "* https://arxiv.org/pdf/1702.01923.pdf\n",
    "* https://arxiv.org/pdf/1809.03684.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
